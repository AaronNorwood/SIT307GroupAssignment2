{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GBC Model Implementation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Group 3</h3>\n",
    "<p>By:<br>\n",
    "    Aaron Norwood,218330434<br>\n",
    "    Joshua Anthony, 219466473<br>\n",
    "    Roger Middenway, 217602784<br>\n",
    "    David Adams, 216110104<br>\n",
    "    Linden Hutchinson, 218384326<br>\n",
    "    Dale Orders, 219106283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Read in the data, store if dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tidying up the data\n",
    "\n",
    "Implementing consistent capitalization and replacing underscores  spaces with hyphens in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert gender to lowercase\n",
    "df['gender'] = df['gender'].apply(lambda x: x.lower())\n",
    "\n",
    "##convert work_type to lowercase ensure consistent spacing \n",
    "df['work_type'] = df['work_type'].apply(lambda x: x.lower().replace('_','-'))\n",
    "\n",
    "##convert residence_type to lowercase\n",
    "df.rename(columns={'Residence_type':'residence_type'}, inplace=True)\n",
    "df['residence_type'] = df['residence_type'].apply(lambda x: x.lower())\n",
    "\n",
    "##convert smoking_status to lowercase ensure consistent spacing \n",
    "df['smoking_status'] = df['smoking_status'].apply(lambda x: x.lower().replace(' ', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Replacing gender with dummy variables for easier visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].str.lower().map({'male': 1, 'female': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Indexes of the outliers with a bmi above 60 for verification purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cap the outliers at a maximum bmi of 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi'] = df['bmi'].apply(lambda bmi_value: bmi_value if 12 < bmi_value < 60 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing BMI values\n",
    "<P>Replace missing BMI values with the average BMI found in rows with the same age and gender<P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check initial number of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 1\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  218\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get number of nulls in df\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Impute missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].apply(lambda x : round(x))\n",
    "\n",
    "m_df = df[df['gender'] == 1]\n",
    "f_df = df[df['gender'] == 0]\n",
    "\n",
    "m_bmi_avg = m_df.groupby('age')['bmi'].mean()\n",
    "f_bmi_avg = f_df.groupby('age')['bmi'].mean()\n",
    "##round to one to fit with other bmi values\n",
    "m_bmi_avg = round(m_bmi_avg,1)\n",
    "f_bmi_avg = round(f_bmi_avg,1)\n",
    "\n",
    "missing_vals = df[df.isnull().any(axis = 1)]\n",
    "\n",
    "for index, row in missing_vals.iterrows():\n",
    "    if row['gender'] == 1:\n",
    "        df.loc[index,['bmi']] = m_bmi_avg[row['age']]\n",
    "    else:\n",
    "        df.loc[index,['bmi']] = f_bmi_avg[row['age']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checking again for nulls to verify imputation success</h3>\n",
    "<p>NOTE: the values with nulls were left in a separate column in case it is needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "gender               1\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing a single missing gender value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##I realised that gender had all been mapped to float, so I've fixed that he\n",
    "df['gender'] = df['gender'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the df used for GBC and Decision Trees\n",
    "### Not using some features which proved not to be helpful for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['id','work_type','residence_type','smoking_status', 'ever_married'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>29.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  hypertension  heart_disease  avg_glucose_level   bmi  stroke\n",
       "0       1   67             0              1             228.69  36.6       1\n",
       "1       0   61             0              0             202.21  29.1       1\n",
       "2       1   80             0              1             105.92  32.5       1\n",
       "3       0   49             0              0             171.23  34.4       1\n",
       "4       0   79             1              0             174.12  24.0       1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic decision tree\n",
    "Very poor recall and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1533,)\n",
      "(1533, 6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1457\n",
      "           1       0.12      0.11      0.11        76\n",
      "\n",
      "    accuracy                           0.92      1533\n",
      "   macro avg       0.54      0.53      0.54      1533\n",
      "weighted avg       0.91      0.92      0.92      1533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df2.drop(['stroke'], axis=1)\n",
    "target = df['stroke']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     data, target, test_size=0.3, random_state=0)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "#clf = clf.fit(X_train,y_train)\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1400,   57],\n",
       "       [  68,    8]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC no SMOTE\n",
    "Also very poor recall and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1533,)\n",
      "(1533, 6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1457\n",
      "           1       0.26      0.07      0.11        76\n",
      "\n",
      "    accuracy                           0.94      1533\n",
      "   macro avg       0.61      0.53      0.54      1533\n",
      "weighted avg       0.92      0.94      0.93      1533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     data, target, test_size=0.3, random_state=0)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(loss='deviance',\n",
    "                                    max_depth=10,\n",
    "                                    learning_rate=0.5,\n",
    "                                    n_estimators=600,\n",
    "                                    random_state=42,\n",
    "                                    criterion='friedman_mse',\n",
    "                                    min_samples_split=0.01).fit(X_train, y_train)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "##gb_clf = gb_clf.fit(X_train,y_train)\n",
    "gb_clf.fit(X_train,y_train)\n",
    "pred = gb_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1443,   14],\n",
       "       [  71,    5]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_smote, y_smote = SMOTE().fit_resample(data, target)\n",
    "\n",
    "#counter = Counter(y_smote)\n",
    "#print('After',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC with SMOTE\n",
    "Much better results, good acc, recall and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Counter({0: 3404, 1: 3404})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1457\n",
      "           1       0.13      0.20      0.15        76\n",
      "\n",
      "    accuracy                           0.89      1533\n",
      "   macro avg       0.54      0.56      0.55      1533\n",
      "weighted avg       0.92      0.89      0.90      1533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3)\n",
    "\n",
    "X_smote, y_smote = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_smote)\n",
    "print('After',counter)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(loss='deviance',\n",
    "                                    max_depth=10,\n",
    "                                    learning_rate=0.5,\n",
    "                                    n_estimators=600,\n",
    "                                    random_state=42,\n",
    "                                    criterion='friedman_mse',\n",
    "                                    min_samples_split=0.01).fit(X_train, y_train)\n",
    "gb_clf.fit(X_smote,y_smote)\n",
    "pred = gb_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1354,  103],\n",
       "       [  61,   15]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
